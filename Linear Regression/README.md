# ğŸ§® Linear Regression Cross-Validation Analysis

<div align="center">

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![Pandas](https://img.shields.io/badge/pandas-v1.3+-green.svg)
![NumPy](https://img.shields.io/badge/numpy-v1.21+-yellow.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-v1.0+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

<i>A comprehensive evaluation of linear regression using four cross-validation strategies</i>

</div>

---

## ï¿½ Overview

This project demonstrates **linear regression** model evaluation using four popular cross-validation techniques in Python:

- **Holdout Validation**
- **Leave-One-Out Cross Validation (LOOCV)**
- **Stratified K-Fold Cross Validation**
- **K-Fold Cross Validation**

Each method's accuracy is compared using the RÂ² score.

> ğŸ¯ **Goal:** Understand how different validation strategies affect model reliability and accuracy.

---

## ğŸ“ Project Structure

```
Linear_Regression/
â”œâ”€â”€ linear_regression_cv.py.py   # Main analysis script
â”œâ”€â”€ sal.csv                     # Dataset (YearsExperience, Salary)
â”œâ”€â”€ README.md                   # This documentation
```

---

## ğŸ› ï¸ Technologies Used

<table align="center">
<tr>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" width="50"/><br><b>Python</b></td>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pandas/pandas-original.svg" width="50"/><br><b>Pandas</b></td>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/numpy/numpy-original.svg" width="50"/><br><b>NumPy</b></td>
<td align="center"><img src="https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png" width="50"/><br><b>scikit-learn</b></td>
</tr>
</table>

---

## âš¡ Quick Start

### ğŸ“‹ Prerequisites

```powershell
pip install pandas numpy scikit-learn
```

### â–¶ï¸ Run the Analysis

```powershell
# Clone the repository
git clone https://github.com/IdealAnkit/Machine_Learning.git

# Navigate to the project directory
cd Machine_Learning/Linear_Regression

# Run the analysis
python linear_regression_cv.py.py
```

---

## ğŸ“Š Data & Features

- **Input:** `sal.csv` (YearsExperience as feature)
- **Target:** Salary (last column)

---

## ï¿½ Analysis Workflow

### 1ï¸âƒ£ Data Loading & Preparation

```python
df = pd.read_csv("sal.csv")
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values
```

### 2ï¸âƒ£ Model Setup

```python
model = LinearRegression()
```

### 3ï¸âƒ£ Validation Techniques

| Method               | Description                        | Best Use Case            |
| -------------------- | ---------------------------------- | ------------------------ |
| ğŸŸ¦ Holdout           | Train/test split (80/20)           | Quick baseline           |
| ğŸŸ© LOOCV             | Each sample is tested once         | Small datasets, unbiased |
| ğŸŸ¨ Stratified K-Fold | Folds preserve target distribution | Imbalanced targets       |
| ğŸŸ§ K-Fold            | Random folds, average results      | General purpose          |

---

## ğŸ§© Step-by-Step Breakdown

<details>
<summary>ğŸ” <b>Detailed process</b></summary>

1. **Holdout Validation**
   - Split data, train, test, compute RÂ²
2. **LOOCV**
   - For each sample: train on all others, test on one
3. **Stratified K-Fold**
   - Bin target, split into stratified folds, train/test
4. **K-Fold**
   - Shuffle, split into 5 folds, train/test
5. **Results**
   - Print RÂ² for each method

</details>

---

## ğŸ“ˆ Sample Output

```
Model Accuracy (RÂ² Score):
(i) Holdout Validation               : 0.9123
(ii) Leave-One-Out CV (LOOCV)        : 0.9056
(iii) Stratified K-Fold CV           : 0.9102
(iv) K-Fold CV                       : 0.9087
```

---

## ğŸ’¡ Key Insights

- **Holdout**: Fast, but can be sensitive to random splits
- **LOOCV**: Most robust for small datasets
- **Stratified K-Fold**: Best for imbalanced targets
- **K-Fold**: Reliable for general use

---

## ï¿½ï¸ Customization

- Change `n_bins` or `n_splits` in the script to adjust folds/bins
- Replace `sal.csv` with your own dataset (same format)

---

## ğŸ† Achievements & Metrics

<table align="center">
<tr>
<td align="center"><h3>10</h3><p>ï¿½ï¸ Samples Analyzed</p></td>
<td align="center"><h3>1</h3><p>ğŸ“Š Feature Used</p></td>
<td align="center"><h3>4</h3><p>ğŸ” Validation Methods</p></td>
<td align="center"><h3>1</h3><p>ğŸ¤– Model Type</p></td>
</tr>
</table>

---

## ï¿½ğŸ“š References

- [scikit-learn documentation](https://scikit-learn.org/stable/documentation.html)
- [Cross-validation strategies](https://scikit-learn.org/stable/modules/cross_validation.html)

---

## ğŸ¤ Contributing

We welcome contributions! You can help by:

- ğŸ Reporting bugs and issues
- ğŸ’¡ Suggesting improvements
- ğŸ“ˆ Adding new validation methods or datasets
- ğŸ“ Improving documentation

---

<div align="center">

![Data Analysis](https://img.shields.io/badge/Data%20Analysis-Complete-brightgreen?style=for-the-badge&logo=chart-dot-js)
![Validation Methods](https://img.shields.io/badge/Validation-4%20Types-blue?style=for-the-badge&logo=check)
![Code Quality](https://img.shields.io/badge/Code%20Quality-High-yellow?style=for-the-badge&logo=code)

### â­ **Show Your Support**

If you found this project helpful, please give it a â­ on GitHub!

[![GitHub stars](https://img.shields.io/github/stars/IdealAnkit/Machine_Learning.svg?style=social&label=Star&maxAge=2592000)](https://github.com/IdealAnkit/Machine_Learning/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/IdealAnkit/Machine_Learning.svg?style=social&label=Fork&maxAge=2592000)](https://github.com/IdealAnkit/Machine_Learning/network/members)
[![GitHub watchers](https://img.shields.io/github/watchers/IdealAnkit/Machine_Learning.svg?style=social&label=Watch&maxAge=2592000)](https://github.com/IdealAnkit/Machine_Learning/watchers)

<i>Made with â¤ï¸ and â˜• for the Machine Learning Community</i>

</div>
